{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "6Tn3OhKBkYaT",
        "outputId": "748ace1d-bc51-46aa-90c3-158aa9e4827e"
      },
      "outputs": [],
      "source": [
        "#importing requiered libraries and data set\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/pet_finder/petfinder-mini.csv\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2yvhe5km0oW",
        "outputId": "33fcfd5b-7a03-4717-8d05-e40f0c8e6b1e"
      },
      "outputs": [],
      "source": [
        "# cheking if there is null parameters\n",
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vo1-ZP1r6ft"
      },
      "outputs": [],
      "source": [
        "# storeing  `AdoptionSpeed` column in variable Y ; storeing `Description` column in variable D to be able to use it in `CountVectorizer()`; storeing the reamaining columns in variable X\n",
        "\n",
        "X = data.drop(['AdoptionSpeed', 'Description'], axis=1)\n",
        "Y = data['AdoptionSpeed']\n",
        "D = data['Description']\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NZWlaHiCb_7"
      },
      "outputs": [],
      "source": [
        "# filling the null parameters\n",
        "D = D.fillna('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RysTytLyCevG",
        "outputId": "5e3daaae-fc11-451c-ff16-b327ff1dfe88"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# cheking if there is any null left\n",
        "D.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYdwNrJmrsHH",
        "outputId": "d9ac0798-fb03-42cd-dc59-a19b207ec29f"
      },
      "outputs": [],
      "source": [
        "# defining `CountVectorizer` and calling it on our D variable\n",
        "cv = CountVectorizer()\n",
        "D_transformed = cv.fit_transform(D)\n",
        "D_transformed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dB8XT5JUnHpw"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "# defining categorical features list for `OneHotEncoder0` and transforming our X variable\n",
        "categorical_features = [\"Type\",\"Breed1\",\"Gender\",\"Color1\",\n",
        "                        \"Color2\",\"MaturitySize\",\"FurLength\",\"Vaccinated\",\n",
        "                        \"Sterilized\",\"Health\"]\n",
        "one_hot=OneHotEncoder()\n",
        "transformer=ColumnTransformer([(\"one_hot\",\n",
        "                               one_hot,\n",
        "                               categorical_features)],\n",
        "                              remainder=\"passthrough\")\n",
        "OH_X = transformer.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MboZwo5Dq3r"
      },
      "outputs": [],
      "source": [
        "from scipy.sparse import hstack\n",
        "# apprnding variable D to OH_X vaiable \n",
        "OH_X_with_text = hstack([OH_X, D_transformed])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O57ESc1WwSqy",
        "outputId": "2223018f-0547-47f3-c703-c5d56baec9e2"
      },
      "outputs": [],
      "source": [
        "# seting up our training and test data\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(OH_X_with_text, Y, test_size=0.2)\n",
        "# defining a base model\n",
        "model_1 = DecisionTreeClassifier()\n",
        "model_1.get_params()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F58tEmfvxCYN"
      },
      "outputs": [],
      "source": [
        "#fitting the base model and testing it\n",
        "model_1.fit(xtrain, ytrain)\n",
        "predictions = model_1.score(xtest, ytest);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "IDGN7iPCxcDv",
        "outputId": "5e4683f0-cd34-4ed3-9408-6a6168979724"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "# ploting the resualt of our base model with confusion matrix\n",
        "y_preds = model_1.predict(xtest)\n",
        "accuracy = model_1.score(xtest, ytest)\n",
        "\n",
        "print(f\"model_1 Accuracy: { accuracy * 100}%\")\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_true=ytest, y_pred=y_preds)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"0\",\"1\",\"2\",\"3\",\"4\"])\n",
        "disp.plot(cmap='Blues', values_format='d')\n",
        "\n",
        "plt.title('Confusion Matrix model_1')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8izu4dDLCZL",
        "outputId": "297bfdff-784e-4015-e8da-620feeabb347"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# defining a second model\n",
        "model_2 = RandomForestClassifier(n_jobs=-1,verbose=1)\n",
        "model_2.get_params()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOhxESZDLJfj",
        "outputId": "f03c43a9-c573-45cc-9b1a-91869e574a6c"
      },
      "outputs": [],
      "source": [
        "# fitting new model and testing it\n",
        "model_2.fit(xtrain, ytrain)\n",
        "predictions = model_2.score(xtest, ytest);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "id": "BfDs_Ji6Lc-h",
        "outputId": "314a2d68-2fa5-498c-d775-82218afd673e"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "#ploting the resualt of the second with confusion matrix\n",
        "y_preds = model_2.predict(xtest)\n",
        "accuracy = model_2.score(xtest, ytest)\n",
        "\n",
        "print(f\"Model_2 Accuracy: { accuracy * 100}%\")\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_true=ytest, y_pred=y_preds)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"0\",\"1\",\"2\",\"3\",\"4\"])\n",
        "disp.plot(cmap='Blues', values_format='d')\n",
        "\n",
        "plt.title('Confusion Matrix mode_2')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbxaPbToLc8R"
      },
      "outputs": [],
      "source": [
        "# defining a library for `GridSearchCV`\n",
        "grid = {'n_estimators': [10,100,1000],\n",
        "       'max_depth': [None,5,10,20],\n",
        "       'max_features': [\"sqrt\",\"log2\"],\n",
        "        'min_samples_split' : [2,4],\n",
        "        'min_samples_leaf' : [1,2]}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngnUQ5obNFuB"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "# defining `evaluate_preds` function to get accuracy_score, precision_score, recall_score and f1_score of the model\n",
        "\n",
        "def evaluate_preds(y_true, y_preds):\n",
        "    accuracy=accuracy_score(y_true,y_preds,average='macro')\n",
        "    percesion=precision_score(y_true,y_preds,average='macro')\n",
        "    recall=recall_score(y_true,y_preds,average='macro')\n",
        "    f1=f1_score(y_true,y_preds)\n",
        "    metrics_dict = {'accuracy' : round(accuracy,2),\n",
        "                   \"percesion\": round( percesion,2),\n",
        "                   \"recall\":round(recall,2),\n",
        "                    'f1' : round(f1,2)\n",
        "                   }\n",
        "    print(f'ACC :{ accuracy*100:2f}%')\n",
        "    print(f'percesion: {percesion:2f}')\n",
        "    print(f'recall: {recall:2f}')\n",
        "    print(f'f1: {f1:2f}')\n",
        "    return metrics_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7nenQJtMg9_"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "# defining `GridSearchCV` model and fitting it\n",
        "gs_clf = GridSearchCV(estimator=model_2,param_grid=grid,cv=2,verbose=1)\n",
        "gs_clf.fit(xtrain,ytrain);\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szWb-NCO18GE",
        "outputId": "9577cbfa-2b6c-41f5-e9fc-eb6f634bf721"
      },
      "outputs": [],
      "source": [
        "# getting the parameters of the model \n",
        "gs_clf.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJahV2iiNnYx"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "# saving our model\n",
        "with open(\"/content/drive/MyDrive/pet_finder/model_2_random_forest_Grid_search_best_param.pkl\", 'wb') as file:\n",
        "    pickle.dump(model_2, file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJ2n1m7jjp5d"
      },
      "outputs": [],
      "source": [
        "# loading the model\n",
        "model_2_GS_params_loaded = pickle.load(open('/content/drive/MyDrive/pet_finder/model_2_random_forest_Grid_search_best_param.pkl','rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFxyuyqJlcjO"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "# chenging the average for `evaluate_preds` function and defining a new function as `evaluate_preds_weighted` \n",
        "def evaluate_preds_weighted(y_true, y_preds):\n",
        "    accuracy = accuracy_score(y_true, y_preds)\n",
        "    precision = precision_score(y_true, y_preds, average='weighted')  # Change average to 'micro', 'macro', or 'weighted'\n",
        "    recall = recall_score(y_true, y_preds, average='weighted')  # Change average to 'micro', 'macro', or 'weighted'\n",
        "    f1 = f1_score(y_true, y_preds, average='weighted')  # Change average to 'micro', 'macro', or 'weighted'\n",
        "\n",
        "    metrics_dict = {\n",
        "        'accuracy': round(accuracy, 2),\n",
        "        'precision': round(precision, 2),\n",
        "        'recall': round(recall, 2),\n",
        "        'f1': round(f1, 2)\n",
        "    }\n",
        "\n",
        "    print(f'ACC: {accuracy * 100:.2f}%')\n",
        "    print(f'Precision: {precision:.2f}')\n",
        "    print(f'Recall: {recall:.2f}')\n",
        "    print(f'F1: {f1:.2f}')\n",
        "\n",
        "    return metrics_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJUXU9VQkRtu",
        "outputId": "cc276916-d101-4b66-af53-e20e8c6bda78"
      },
      "outputs": [],
      "source": [
        "#makeing prediction with loaded model and geting accuracy_score, precision_score, recall_score and f1_score with new function\n",
        "model_2_GS_params_loaded_y_preds = model_2_GS_params_loaded.predict(xtest)\n",
        "\n",
        "model_2_GS_params_loaded_metrics= evaluate_preds_weighted(ytest, model_2_GS_params_loaded_y_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "jVEZJu3zkRqe",
        "outputId": "0cf26c39-cd8e-481f-c4b3-51fc89fac521"
      },
      "outputs": [],
      "source": [
        "# ploting the model resaults using confusion matrix\n",
        "print(f'Model accuracy on test set : {model_2_GS_params_loaded.score(xtest,ytest)*100}%')\n",
        "\n",
        "# Display the confusion matrix\n",
        "cm = confusion_matrix(y_true=ytest, y_pred=model_2_GS_params_loaded_y_preds)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"0\",\"1\",\"2\",\"3\",\"4\"])\n",
        "disp.plot(cmap='Blues', values_format='d')\n",
        "\n",
        "plt.title('Confusion Matrix mode_2_GridSearchCV')\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWwFXYJEjptw"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "# saving model\n",
        "with open(\"/content/drive/MyDrive/pet_finder/model_2_random_forest_Grid_search_best_param_88%.pkl\", 'wb') as file:\n",
        "    pickle.dump(model_2_GS_params_loaded, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05RpbmdnMgkZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNz_-epWLc6P"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXkLimGSLc3r"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
